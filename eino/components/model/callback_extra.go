package model

import (
	"github.com/favbox/eino/callbacks"
	"github.com/favbox/eino/schema"
)

// TokenUsage 记录模型的令牌使用统计信息。
//
// 用于跟踪模型调用的资源消耗，包括输入令牌数、输出令牌数等，
// 对于监控模型成本和优化使用量非常重要。
//
// 设计理念：
// 令牌使用统计是模型调用的核心指标之一，
// 它直接关联到成本控制、性能优化和资源配置。
// 通过详细的令牌分解，我们可以：
//   - 精确计算 API 调用成本
//   - 识别优化机会（如减少提示词长度）
//   - 监控资源使用趋势
//   - 设置合理的配额限制
//
// 成本计算示例：
//
//	假设 OpenAI GPT-4 的定价是：
//	  - 输入：$0.03/1K tokens
//	  - 输出：$0.06/1K tokens
//	本次调用成本 = (PromptTokens/1000)*0.03 + (CompletionTokens/1000)*0.06
type TokenUsage struct {
	// PromptTokens 是输入提示词的令牌数量。
	//
	// 包括本次请求的所有输入令牌：
	//   - 对话历史中的所有消息
	//   - 当前用户输入的消息
	//   - 系统提示词（如果有）
	//   - 工具描述（如果使用了工具）
	//
	// 这个指标反映了模型的"理解成本"。
	// 优化提示词长度是降低输入成本的关键。
	//
	// 常见优化策略：
	//   - 压缩对话历史（保留最近 N 轮对话）
	//   - 精简系统提示词（去除冗余描述）
	//   - 合理使用工具（工具描述会增加提示词长度）
	//   - 复用常用模板（减少重复内容）
	//
	// 注意事项：
	//   - 不同模型对令牌的计算方法可能有细微差异
	//   - 包括不可见字符（如空格、换行）
	//   - 系统提示词可能在大规模使用时会被缓存
	PromptTokens int

	// PromptTokenDetails 是输入提示词令牌的详细分解。
	//
	// 提供更细粒度的输入令牌统计信息，
	// 帮助分析令牌使用的具体情况。
	//
	// 详细分解的价值：
	//   - 识别高成本组件（哪个消息/工具占用了最多令牌）
	//   - 优化特定类型的提示词
	//   - 比较不同提示词策略的效果
	//   - 为成本归因提供精确数据
	//
	// 使用场景：
	//   - 分析对话历史对成本的影响
	//   - 评估工具使用的成本效益
	//   - 监控系统提示词的优化效果
	PromptTokenDetails PromptTokenDetails

	// CompletionTokens 是模型生成输出的令牌数量。
	//
	// 这是模型生成回复的令牌总数，
	// 反映了模型的"生成成本"。
	//
	// 该值通常用于：
	//   - 计算输出成本
	//   - 监控响应长度
	//   - 设置输出限制
	//
	// 成本控制策略：
	//   - 设置 MaxTokens 限制生成长度
	//   - 使用 stop 序列提前终止
	//   - 优化提示词以获得更简洁的回答
	//   - 采用分页或分段生成策略
	//
	// 性能相关性：
	//   - 输出令牌数直接影响响应延迟
	//   - 更多的令牌意味着更长的计算时间
	//   - 流式输出可以改善用户体验
	CompletionTokens int

	// TotalTokens 是本次请求的令牌总数。
	//
	// 计算公式：TotalTokens = PromptTokens + CompletionTokens
	//
	// 这是最核心的指标，用于：
	//   - 计算总成本（输入+输出）
	//   - 监控 API 配额使用
	//   - 设置请求限制
	//
	// 配额管理最佳实践：
	//   - 监控每日/每月的总令牌使用量
	//   - 设置阈值告警（如使用率达到 80% 时告警）
	//   - 实施限流策略防止超出配额
	//   - 为不同用户/应用设置独立的配额
	//
	// 与其他指标的关系：
	//   - 可以计算平均响应长度（Completion/Prompt 比率）
	//   - 可以评估提示词效率（每单位输入产生的输出）
	//   - 用于 A/B 测试不同策略的效果
	TotalTokens int
}

// PromptTokenDetails 提供输入提示词令牌的详细分解信息。
//
// 用于更精细地分析令牌使用情况，
// 帮助优化提示词和降低成本。
//
// 设计理念：
// 现代大语言模型支持上下文缓存机制，
// 可以复用之前见过的内容，从而降低成本和延迟。
// 通过详细分解不同类型的令牌使用，
// 开发者可以：
//   - 识别可优化的重复内容
//   - 评估缓存策略的效果
//   - 平衡响应质量和成本
//
// 应用场景：
//   - 对话系统：缓存常用的系统提示词
//   - 多轮交互：复用用户档案和背景信息
//   - 工具集成：复用工具描述和使用说明
//   - 批量处理：识别多个请求间的共同内容
type PromptTokenDetails struct {
	// CachedTokens 是提示词中缓存的令牌数量。
	//
	// 缓存令牌是指模型之前已经处理过且可以重复使用的令牌，
	// 例如：
	//   - 对话历史中常用短语
	//   - 标准系统提示词
	//   - 重复使用的工具描述
	//
	// 缓存令牌的优势：
	//   - 不需要重新计算，降低延迟
	//   - 不计入成本或按折扣计费
	//   - 提高模型响应速度
	//
	// 该指标用于分析缓存效率和优化提示词结构。
	//
	// 缓存优化策略：
	//   - 标准化系统提示词格式
	//   - 提取常用业务模板
	//   - 使用变量插入减少重复
	//   - 合理设计对话上下文
	//
	// 与成本的关系：
	//   - 缓存令牌通常免费或低价
	//   - 缓存命中率 = CachedTokens / PromptTokens
	//   - 高缓存率显著降低长期成本
	//
	// 注意事项：
	//   - 不同提供商的缓存策略不同
	//   - 缓存通常有时间和大小限制
	//   - 频繁变更的提示词会影响缓存效果
	//   - 某些模型可能不公开详细的缓存信息
	CachedTokens int
}

// Config 定义了模型组件的完整配置信息。
//
// 这个配置结构体包含了调用模型时需要的所有参数，
// 与 Option 结构体不同，Config 是实际使用的配置值，
// 而 Option 是用于构建配置的函数式选项。
//
// 设计理念：
// Config 代表了"已解析并应用的配置"，
// 它反映了最终的、实际生效的参数设置。
// 与 Option（待解析的选项函数）相比，Config 具有以下特点：
//   - 是具体的、可直接使用的值
//   - 已经过验证和默认值处理
//   - 适合在回调中记录和审计
//
// 配置优先级：
//  1. 显式传入的参数值
//  2. 用户自定义的默认值
//  3. 提供商的默认设置
//  4. 模型的内置限制
type Config struct {
	// Model 指定要使用的模型名称。
	//
	// 例如："gpt-3.5-turbo"、"gpt-4"、"claude-3-sonnet" 等。
	// 不同提供商的模型名称格式可能不同。
	//
	// 该字段将影响：
	//   - 模型的行为和能力
	//   - API 调用的端点和参数
	//   - 计费方式
	//
	// 模型选择原则：
	//   - 简单任务：选择成本效益高的模型（如 GPT-3.5）
	//   - 复杂推理：选择能力强的模型（如 GPT-4、Claude-3）
	//   - 多语言：选择支持多语言的模型
	//   - 实时性：选择延迟低的流式模型
	//
	// 版本管理：
	//   - 建议固定模型版本号避免意外行为变化
	//   - 定期评估升级到新版本的成本和收益
	//   - 使用 A/B 测试比较不同模型的效果
	//
	// 示例配置：
	//   - 轻量级：Model: "gpt-3.5-turbo"
	//   - 高质量：Model: "gpt-4o"
	//   - 多模态：Model: "claude-3-5-sonnet-20241022"
	Model string

	// MaxTokens 限制模型生成的最大令牌数。
	//
	// 当达到此限制时，模型将停止生成，
	// 并返回 finish_reason 为 "length"。
	//
	// 使用场景：
	//   - 控制成本（按令牌计费）
	//   - 限制响应长度
	//   - 防止过长输出
	//
	// 建议值：
	//   - 短回复：50-200
	//   - 中等回复：500-1000
	//   - 长文档：2000-4000
	//   - 0 表示使用模型默认值
	//
	// 成本控制策略：
	//   - 根据业务场景设置合理的上限
	//   - 监控实际使用情况动态调整
	//   - 对于无限对话场景，优先使用流式输出
	//   - 结合 Temperature 防止意外的长输出
	//
	// 与质量的关系：
	//   - 过低的 MaxTokens 可能导致输出被截断
	//   - 过高的 MaxTokens 浪费成本且可能降低质量
	//   - 建议通过历史数据分析确定最佳值
	//
	// 实际案例：
	//   - 客服机器人：MaxTokens=200
	//   - 代码生成：MaxTokens=1000
	//   - 长文档总结：MaxTokens=2000
	//   - 流式对话：MaxTokens=500
	MaxTokens int

	// Temperature 控制模型输出的随机性和创造性。
	//
	// 值越高（接近 2.0），输出越随机和多样化；
	// 值越低（接近 0.0），输出越确定和一致。
	//
	// 建议值：
	//   - 0.0-0.3：确定性输出，适合代码生成、事实查询
	//   - 0.3-0.7：平衡输出，适合大多数对话场景
	//   - 0.7-1.0：创造性输出，适合头脑风暴、创意写作
	//   - >1.0：高度随机（不推荐）
	//
	// 工作原理：
	//   - Temperature 通过缩放 logits（原始得分）来控制随机性
	//   - 低温度使概率分布更尖锐，高温度使其更平缓
	//   - Temperature=0 几乎总是选择最可能的下一个词
	//
	// 实际应用场景：
	//   - 事实问答：Temperature=0.1（确保准确性）
	//   - 创意写作：Temperature=0.8（增加多样性）
	//   - 代码生成：Temperature=0.2（减少语法错误）
	//   - 角色扮演：Temperature=0.7（保持角色一致性）
	//
	// 调试技巧：
	//   - 如果输出太相似，尝试增加 Temperature
	//   - 如果输出太随机，尝试降低 Temperature
	//   - 可以固定随机种子获得可重复的结果
	Temperature float32

	// TopP 控制模型输出的多样性（核心采样）。
	//
	// 与 Temperature 类似，但更关注词汇选择的多样性。
	// 只考虑累积概率为 TopP 的最可能词汇。
	//
	// 使用建议：
	//   - 与 Temperature 不要同时设置很高的值
	//   - 0.9 是常见的安全值
	//   - 较低的 TopP 产生更集中的输出
	//   - 较高的 TopP 产生更多样化的输出
	//
	// 核采样原理：
	//   - 选择累积概率达到 TopP 的最小词汇集合
	//   - 从这个集合中随机采样下一个词
	//   - 忽略低概率的词汇，减少噪声
	//
	// 对比 Temperature：
	//   - TopP 控制"哪些词可以考虑"
	//   - Temperature 控制"如何从候选中选择"
	//   - TopP 更动态，候选集合大小根据上下文变化
	//
	// 优化策略：
	//   - 对于事实性任务：TopP=0.5（严格筛选）
	//   - 对于创造性任务：TopP=0.9（广泛选择）
	//   - 同时调整 Temperature 和 TopP 时要小心
	//   - 建议一个高一个低，避免过度随机
	//
	// 常见陷阱：
	//   - TopP=1.0 等同于不使用核采样
	//   - 过低的 TopP 可能导致词汇贫乏
	//   - 过高的 TopP 可能引入不相关的内容
	TopP float32

	// Stop 定义模型的停止词列表。
	//
	// 当模型生成到这些词汇或短语时，会提前停止生成。
	//
	// 使用场景：
	//   - 控制输出边界（如在列表项后停止）
	//   - 避免不必要的结尾语句
	//   - 配合格式要求使用
	//
	// 示例：
	//   - []string{"\n"}：在换行处停止
	//   - []string{"END"}：遇到 END 字符串时停止
	//   - []string{"\n", "。"}：在换行或句号处停止
	//
	// 高级用法：
	//   - JSON 输出：Stop=[]string{"\n}", "}"} 确保格式完整
	//   - 代码块：Stop=[]string{"```"} 防止额外解释
	//   - 列表项：Stop=[]string{"\n-", "\n*"} 控制列表长度
	//
	// 设计原则：
	//   - 选择常见的、不会在中间出现的词汇
	//   - 考虑停止词对用户体验的影响
	//   - 在系统提示词中明确说明停止条件
	//
	// 常见问题：
	//   - 停止词可能永远不出现（导致超时）
	//   - 停止词可能出现在意外位置（截断内容）
	//   - 某些语言的分词方式可能影响停止检测
	//
	// 与 MaxTokens 的配合：
	//   - Stop 是"优雅停止"机制
	//   - MaxTokens 是"强制停止"机制
	//   - 建议同时使用两者以获得最佳效果
	Stop []string
}

// CallbackInput 定义了模型回调的输入参数。
//
// 在模型的 OnStart 回调中，这个结构体将被传递给回调处理器，
// 包含了模型执行所需的所有信息和配置。
//
// 设计理念：
// CallbackInput 是模型调用的"完整快照"，
// 它捕获了模型执行前的所有关键信息：
//   - 对话上下文（Messages）
//   - 可用能力（Tools）
//   - 执行策略（ToolChoice）
//   - 模型配置（Config）
//
// 这种全面的信息捕获使得回调处理器可以：
//   - 审计和记录每次调用的完整参数
//   - 基于配置执行不同的处理逻辑
//   - 分析使用模式和优化机会
//   - 实现成本控制和性能监控
//
// 最佳实践：
//   - 在 OnStart 回调中记录输入信息用于调试
//   - 验证配置参数的合理性
//   - 基于 ToolChoice 实现路由逻辑
//   - 使用 Extra 字段传递业务相关的元数据
type CallbackInput struct {
	// Messages 是要发送给模型的消息列表。
	//
	// 这是对话的核心内容，包含：
	//   - 对话历史消息（用户、助手、系统）
	//   - 当前用户的输入消息
	//   - 按时间顺序排列
	//
	// 每个消息包含：
	//   - Role：消息角色（user/assistant/system）
	//   - Content：消息内容
	//   - ToolCalls：工具调用信息（如果有）
	//
	// 消息序列的重要性：
	//   - 上下文连贯性：消息顺序直接影响模型的"记忆"
	//   - 角色区分：不同角色的消息有不同的处理方式
	//   - 工具调用：ToolCalls 记录了模型发起的工具请求
	//
	// 性能优化建议：
	//   - 避免过长对话历史（建议保留最近 10-20 轮）
	//   - 定期总结和压缩历史内容
	//   - 对于长文档，考虑分段处理
	//   - 系统提示词应该简洁明确
	//
	// 安全考虑：
	//   - 验证用户输入内容的合法性
	//   - 过滤敏感信息（API keys、密码等）
	//   - 考虑对话内容的合规性
	//
	// 调试技巧：
	//   - 在回调中记录消息数量和总长度
	//   - 监控 Token 使用情况
	//   - 分析消息分布（系统/用户/助手比例）
	Messages []*schema.Message

	// Tools 是模型可用的工具列表。
	//
	// 仅当使用支持工具调用的模型时有效。
	// 每个工具包含：
	//   - Name：工具名称
	//   - Description：工具描述
	//   - Parameters：工具参数模式（JSON Schema）
	//
	// 用于工具调用功能，如：
	//   - 函数调用
	//   - API 请求
	//   - 数据查询
	//
	// 工具设计原则：
	//   - 描述应该清晰明确，帮助模型理解何时使用
	//   - 参数模式应该完整定义，避免模型猜测
	//   - 工具名称应该具有描述性
	//   - 避免过多工具（一般不超过 10 个）
	//
	// 工具调用的生命周期：
	//   1. 模型根据用户输入决定是否调用工具
	//   2. 模型生成工具调用请求（ToolCall）
	//   3. 工具执行器处理调用并返回结果
	//   4. 模型接收工具结果并继续生成
	//
	// 性能考虑：
	//   - 工具描述会增加提示词长度
	//   - 过多工具可能降低模型决策准确性
	//   - 建议按功能分组，只暴露相关工具
	//   - 定期评估工具使用的频率和效果
	//
	// 最佳实践：
	//   - 为每个工具提供简洁的使用示例
	//   - 确保参数模式与实际实现一致
	//   - 使用工具调用的日志进行监控和分析
	Tools []*schema.ToolInfo

	// ToolChoice 控制模型如何选择和使用工具。
	//
	// 可以设置为：
	//   - ToolChoiceAuto：模型自主决定是否使用工具
	//   - ToolChoiceForced：强制使用工具（如果可用）
	//   - ToolChoiceNone：禁用工具调用
	//
	// 对于不启用工具的模型，此字段为 nil。
	//
	// 选择策略详解：
	//   Auto：
	//     - 模型根据对话内容智能判断
	//     - 适合开放式对话场景
	//     - 可能错过工具调用机会
	//     - 需要良好的工具描述
	//
	//   Forced：
	//     - 强制模型必须选择并调用一个工具
	//     - 适合工具驱动的业务流程
	//     - 确保工具被使用，但可能导致错误调用
	//     - 需要模型准确理解工具能力
	//
	//   None：
	//     - 完全禁用工具功能
	//     - 适合纯文本生成场景
	//     - 降低复杂度，提高响应速度
	//     - 减少成本（无需处理工具调用）
	//
	// 应用场景：
	//   - 客服机器人：ToolChoiceAuto 或 Forced
	//   - 代码生成：ToolChoiceNone
	//   - 数据查询：ToolChoiceForced
	//   - 创意写作：ToolChoiceAuto
	//
	// 监控要点：
	//   - 记录工具调用频率和成功率
	//   - 分析工具选择的准确性
	//   - 监控不同策略的效果差异
	//   - 评估工具使用对成本的影响
	ToolChoice *schema.ToolChoice

	// Config 是模型的完整配置信息。
	//
	// 包含所有影响模型行为的参数：
	//   - 模型名称
	//   - 生成参数（温度、TopP、MaxTokens）
	//   - 停止词列表
	//
	// 回调处理器可以使用此配置：
	//   - 记录调用的参数
	//   - 验证配置是否合法
	//   - 根据配置做不同处理
	//
	// 配置审计的重要性：
	//   - 合规要求：记录谁在何时使用了什么模型
	//   - 成本分析：不同配置的成本差异
	//   - 质量保证：确保配置符合业务要求
	//   - 故障排查：回溯问题出现时的配置状态
	//
	// 配置验证建议：
	//   - 检查模型名称是否有效和可用
	//   - 验证数值参数是否在合理范围内
	//   - 确保停止词不会影响正常输出
	//   - 检查是否存在过时的配置组合
	//
	// 动态配置策略：
	//   - 基于消息复杂度调整 Temperature
	//   - 根据历史对话长度调整 MaxTokens
	//   - 基于工具可用性选择 ToolChoice
	//   - 根据用户等级选择不同模型
	//
	// 配置版本管理：
	//   - 为每次配置变更生成唯一标识
	//   - 记录配置变更的原因和影响
	//   - 保留配置历史用于回溯分析
	//   - 支持配置回滚到之前版本
	Config *Config

	// Extra 是额外的回调信息。
	//
	// 用于传递与具体实现相关的额外数据，
	// 如：
	//   - 请求 ID
	//   - 调用来源
	//   - 业务特定标识
	//
	// 这个字段提供了灵活性，
	// 允许在不修改核心结构的情况下添加新信息。
	//
	// 常见用途示例：
	//   - trace_id：链路追踪标识
	//   - user_id：用户身份标识
	//   - session_id：会话标识
	//   - source：调用来源（web/mobile/api）
	//   - priority：请求优先级
	//   - tenant_id：租户标识
	//   - client_version：客户端版本
	//   - request_source：请求发起方
	//
	// 数据流传递：
	//   - OnStart：Extra 信息注入到回调中
	//   - OnEnd：可以读取和修改 Extra
	//   - OnError：错误处理可以利用 Extra 信息
	//   - 跨组件：Extra 可以传递到下游组件
	//
	// 最佳实践：
	//   - 使用结构化的键名（如 snake_case 或 camelCase）
	//   - 避免在 Extra 中存储敏感信息
	//   - 记录 Extra 的变更历史
	//   - 定期清理不再需要的 Extra 数据
	//
	// 注意事项：
	//   - Extra 是 map 类型，需要注意并发安全
	//   - 大量数据可能影响性能
	//   - 不同组件间的 Extra 命名应统一
	//   - 建议为 Extra 添加 schema 验证
	Extra map[string]any
}

// CallbackOutput 定义了模型回调的输出结果。
//
// 在模型的 OnEnd 回调中，这个结构体将被传递给回调处理器，
// 包含了模型执行的结果和统计信息。
//
// 设计理念：
// CallbackOutput 是模型调用的"完整结果快照"，
// 它记录了模型执行后的所有关键产出：
//   - 最终输出（Message）
//   - 实际配置（Config）
//   - 资源消耗（TokenUsage）
//   - 扩展信息（Extra）
//
// 这种全面的结果捕获使得回调处理器可以：
//   - 分析模型的输出质量和效果
//   - 计算和跟踪实际的资源消耗
//   - 审计模型执行的完整过程
//   - 识别优化机会和性能瓶颈
//
// 完整性保证：
//   - Message 字段确保输出内容不丢失
//   - Config 字段揭示实际生效的配置
//   - TokenUsage 字段提供精确的成本数据
//   - Extra 字段支持自定义扩展信息
//
// 监控价值：
//   - 构建完整的调用链路追踪
//   - 分析模型性能和质量指标
//   - 实现成本核算和预算控制
//   - 优化配置和提示词策略
type CallbackOutput struct {
	// Message 是模型生成的消息。
	//
	// 这是模型的最终输出结果，包含：
	//   - Role：通常为 "assistant"
	//   - Content：模型生成的文本内容
	//   - ToolCalls：模型请求的工具调用（如果有）
	//
	// 这个消息可以直接发送给用户或用于后续处理。
	//
	// 内容分析要点：
	//   - 检查回复是否符合预期格式
	//   - 分析回复的完整性和准确性
	//   - 验证是否包含不适当内容
	//   - 记录工具调用的详细信息
	//
	// ToolCalls 的处理：
	//   - ToolCalls 表示模型请求的工具调用
	//   - 包含工具名称和参数信息
	//   - 需要工具执行器处理并返回结果
	//   - 模型会继续处理工具结果
	//
	// 输出质量评估：
	//   - 测量响应长度和复杂度
	//   - 检查是否被截断（通过 finish_reason）
	//   - 分析重复或循环内容
	//   - 评估用户满意度和相关性
	//
	// 后续处理流程：
	//   - 直接发送给用户（简单场景）
	//   - 触发工具调用（需要外部数据）
	//   - 传递给下一个组件（复杂编排）
	//   - 存储到历史记录（多轮对话）
	//
	// 错误检测：
	//   - 空消息或错误提示
	//   - 格式不符合要求
	//   - 包含敏感或不当内容
	//   - 工具调用参数错误
	Message *schema.Message

	// Config 是实际使用的模型配置。
	//
	// 可能与 CallbackInput 中的配置不同，
	// 因为模型可能：
	//   - 应用了默认值
	//   - 调整了非法参数
	//   - 应用了提供商的限制
	//
	// 回调处理器可以使用此信息：
	//   - 记录最终使用的参数
	//   - 比较预期与实际的配置差异
	//   - 监控配置变更的影响
	//
	// 配置差异分析：
	//   - 记录所有与输入配置不同的字段
	//   - 分析差异产生的原因和影响
	//   - 识别需要优化的配置项
	//   - 预测未来可能的配置调整
	//
	// 常见配置调整场景：
	//   - MaxTokens 超过模型限制被自动调整
	//   - Temperature 被限制在模型支持范围内
	//   - 不支持的 Stop 词被过滤
	//   - Model 名称被更正为有效版本
	//
	// 审计价值：
	//   - 确保配置变更符合预期
	//   - 识别意外的配置调整
	//   - 追踪模型版本更新带来的影响
	//   - 合规和监管要求
	//
	// 优化建议：
	//   - 定期检查配置差异的频率和模式
	//   - 更新配置以匹配模型的实际能力
	//   - 预检配置避免运行时调整
	//   - 建立配置最佳实践文档
	//
	// 与输入配置的对比：
	//   - 标记所有被修改的字段
	//   - 计算配置变更对输出的影响
	//   - 识别可能的性能问题
	//   - 评估成本变化
	Config *Config

	// TokenUsage 是本次请求的令牌使用统计。
	//
	// 包含详细的令牌消耗信息：
	//   - 输入令牌数（PromptTokens）
	//   - 输出令牌数（CompletionTokens）
	//   - 总令牌数（TotalTokens）
	//   - 缓存令牌数（CachedTokens）
	//
	// 用于：
	//   - 计算 API 调用成本
	//   - 监控资源使用情况
	//   - 优化提示词长度
	//   - 生成使用报告
	//
	// 成本分析维度：
	//   - 单次调用成本：基于 TotalTokens 计算
	//   - 输入成本：基于 PromptTokens 计算
	//   - 输出成本：基于 CompletionTokens 计算
	//   - 缓存节省：基于 CachedTokens 计算
	//
	// 优化机会识别：
	//   - 识别过长的提示词（高 PromptTokens）
	//   - 捕获冗长的输出（高 CompletionTokens）
	//   - 评估缓存效果（CachedTokens 比例）
	//   - 分析平均响应长度（Completion/Prompt 比）
	//
	// 预算控制策略：
	//   - 设置单次调用 Token 限制
	//   - 监控每日/每月总 Token 使用量
	//   - 实施用户级别的配额控制
	//   - 基于 Token 使用量实施分级定价
	//
	// 性能关联：
	//   - Token 数量与响应延迟正相关
	//   - 缓存 Token 可以显著降低延迟
	//   - 长输出可能导致超时或截断
	//   - 流式输出可以改善用户体验
	//
	// 报告和可视化：
	//   - Token 使用趋势图
	//   - 不同模型的成本对比
	//   - 提示词优化效果追踪
	//   - 用户/应用级别的使用统计
	//
	// 异常检测：
	//   - 异常高的 Token 使用量
	//   - 突然的成本激增
	//   - 缓存命中率异常下降
	//   - 与预期行为的显著偏差
	TokenUsage *TokenUsage

	// Extra 是额外的回调输出信息。
	//
	// 用于传递与具体实现相关的额外结果数据，
	// 如：
	//   - 响应时间
	//   - 错误码
	//   - 业务特定标识
	//
	// 这个字段与 CallbackInput.Extra 对应，
	// 允许在回调链路中传递和修改信息。
	//
	// 输出指标示例：
	//   - duration_ms：执行时间（毫秒）
	//   - latency_p95：95 分位数延迟
	//   - status_code：响应状态码
	//   - error_msg：错误信息（如果有）
	//   - finish_reason：完成原因（stop/length/error）
	//
	// 质量指标示例：
	//   - relevance_score：相关性评分
	//   - coherence_score：连贯性评分
	//   - toxicity_score：内容安全性评分
	//   - factuality_score：事实准确性评分
	//
	// 业务指标示例：
	//   - user_satisfaction：用户满意度
	//   - conversion_rate：转化率
	//   - engagement_score：参与度评分
	//   - feedback_score：反馈评分
	//
	// 链路追踪信息：
	//   - span_id：调用链路中的子调用 ID
	//   - parent_span_id：父调用 ID
	//   - trace_flags：链路追踪标志
	//   - correlation_id：关联 ID
	//
	// 数据演化过程：
	//   - 输入：Extra 携带初始信息（用户 ID、请求 ID 等）
	//   - 处理：回调处理器读取并可能修改 Extra
	//   - 输出：Extra 包含处理结果和新的指标
	//   - 传递：Extra 可以继续传递给下游组件
	//
	// 使用模式：
	//   - 监控：记录性能和质量指标
	//   - 审计：追踪业务相关的决策和数据
	//   - 调试：在开发和测试阶段记录详细信息
	//   - 告警：标记需要关注的情况
	//
	// 与 CallbackInput.Extra 的关联：
	//   - 输入 Extra 提供上下文信息
	//   - 输出 Extra 反映处理结果
	//   - 可以对比输入和输出了解处理过程
	//   - 支持增量式的元数据积累
	Extra map[string]any
}

// ConvCallbackInput 将通用回调输入转换为模型特定的回调输入。
//
// 这是类型转换函数，用于在回调系统中统一不同来源的输入类型。
//
// 转换逻辑：
//  1. 如果输入已经是 *CallbackInput（组件实现内触发），直接返回
//  2. 如果输入是 []*schema.Message（图节点注入），包装为 *CallbackInput
//  3. 其他类型返回 nil
//
// 使用场景：
//   - 当回调被图形编排节点注入时
//   - 当在组件内部直接触发回调时
//   - 需要统一处理不同来源的回调输入时
//
// 参数：
//   - src: 通用回调输入（callbacks.CallbackInput）
//
// 返回：
//   - *CallbackInput: 模型特定的回调输入，或 nil（如果类型不匹配）
//
// 设计理念：
// 在 Eino 的编排框架中，同一个组件可能被多种方式调用：
//   - 直接调用（组件实现内触发）：传入完整的 CallbackInput
//   - 图形编排注入（图节点注入）：传入接口参数（如 []*schema.Message）
//
// 此转换函数的使命是：
//   - 统一不同来源的输入格式
//   - 提供类型安全的转换
//   - 简化回调处理器的实现
//   - 支持灵活的组件组合
//
// 转换策略详解：
//
//	*CallbackInput → 直接返回：
//	  - 组件内部直接触发的回调
//	  - 已经包含完整的输入信息
//	  - 跳过转换以提高性能
//
//	[]*schema.Message → 包装为新实例：
//	  - 来自图形编排节点的注入
//	  - 遵循 Chat Model 的标准接口
//	  - 包装为完整 CallbackInput 结构
//
//	其他类型 → 返回 nil：
//	  - 不支持的输入类型
//	  - 防止意外的类型错误
//	  - 回调处理器应检查返回值
//
// 错误处理建议：
//   - 检查转换结果是否为 nil
//   - 为 nil 结果提供默认行为或错误日志
//   - 记录不支持类型的出现频率
//   - 考虑添加类型断言的详细错误信息
//
// 性能考虑：
//   - 直接返回的场景零拷贝转换
//   - 包装场景仅创建轻量级结构
//   - 不进行深拷贝，引用原数据
//   - 避免不必要的内存分配
//
// 示例：
//
//	// 在组件实现内
//	input := &model.CallbackInput{Messages: msgs}
//	converted := model.ConvCallbackInput(input)
//	// converted == input
//
//	// 在图形节点中
//	input := []*schema.Message{...}
//	converted := model.ConvCallbackInput(input)
//	// converted 是新的 *CallbackInput，Messages 字段被设置
func ConvCallbackInput(src callbacks.CallbackInput) *CallbackInput {
	switch t := src.(type) {
	case *CallbackInput: // 当回调在组件实现内触发时，输入通常已经是类型化的 *model.CallbackInput
		return t
	case []*schema.Message: // 当回调被图形节点注入（不是组件实现自身触发）时，输入是 Chat Model 接口的输入，即 []*schema.Message
		return &CallbackInput{
			Messages: t,
		}
	default:
		return nil
	}
}

// ConvCallbackOutput 将通用回调输出转换为模型特定的回调输出。
//
// 这是类型转换函数，用于在回调系统中统一不同来源的输出类型。
//
// 转换逻辑：
//  1. 如果输出已经是 *CallbackOutput（组件实现内触发），直接返回
//  2. 如果输出是 *schema.Message（图节点注入），包装为 *CallbackOutput
//  3. 其他类型返回 nil
//
// 使用场景：
//   - 当回调被图形编排节点注入时
//   - 当在组件内部直接触发回调时
//   - 需要统一处理不同来源的回调输出时
//
// 参数：
//   - src: 通用回调输出（callbacks.CallbackOutput）
//
// 返回：
//   - *CallbackOutput: 模型特定的回调输出，或 nil（如果类型不匹配）
//
// 设计理念：
// 与 ConvCallbackInput 类似，ConvCallbackOutput 旨在统一不同来源的输出格式。
// 在 Eino 的编排系统中，组件输出可能有两种形式：
//   - 直接输出：完整的 CallbackOutput（包含 TokenUsage、Config 等）
//   - 图形注入：简单的 Message（遵循接口规范）
//
// 此转换函数的价值：
//   - 保持接口的一致性和简洁性
//   - 允许组件以不同方式集成到编排图中
//   - 简化下游组件的处理逻辑
//   - 提供渐进式的能力增强
//
// 转换策略详解：
//
//	*CallbackOutput → 直接返回：
//	  - 组件内部直接返回的完整输出
//	  - 包含所有详细的统计信息
//	  - 保持数据的完整性和精确性
//
//	*schema.Message → 轻量级包装：
//	  - 来自图形编排的标准接口
//	  - 最小化的输出信息
//	  - 动态补充默认统计信息
//
//	其他类型 → 返回 nil：
//	  - 不支持的输出格式
//	  - 触发错误处理或降级逻辑
//	  - 防止类型错误传播
//
// 动态补充机制：
// 当包装 *schema.Message 为 *CallbackOutput 时：
//   - Message：使用传入的消息内容
//   - Config：设为 nil（未知实际配置）
//   - TokenUsage：设为 nil（未计算令牌使用）
//   - Extra：设为 nil（无额外信息）
//
// 这种设计允许：
//   - 快速原型开发和测试
//   - 简化简单场景的使用
//   - 逐步添加更多功能
//   - 向下兼容不同版本
//
// 性能特性：
//   - 零拷贝转换（直接返回场景）
//   - 最小内存分配（包装场景）
//   - 浅拷贝引用，共享底层数据
//   - 避免不必要的序列化/反序列化
//
// 最佳实践建议：
//   - 在需要详细统计信息的场景，直接返回 *CallbackOutput
//   - 在快速集成场景，可以使用 *schema.Message
//   - 定期审计 nil 字段的频率和原因
//   - 考虑为包装后的输出补充更多信息
//
// 示例：
//
//	// 在组件实现内
//	output := &model.CallbackOutput{Message: msg}
//	converted := model.ConvCallbackOutput(output)
//	// converted == output
//
//	// 在图形节点中
//	output := &schema.Message{...}
//	converted := model.ConvCallbackOutput(output)
//	// converted 是新的 *CallbackOutput，Message 字段被设置
func ConvCallbackOutput(src callbacks.CallbackOutput) *CallbackOutput {
	switch t := src.(type) {
	case *CallbackOutput: // 当回调在组件实现内触发时，输出通常已经是类型化的 *model.CallbackOutput
		return t
	case *schema.Message: // 当回调被图形节点注入（不是组件实现自身触发）时，输出是 Chat Model 接口的输出，即 *schema.Message
		return &CallbackOutput{
			Message: t,
		}
	default:
		return nil
	}
}
